The algorithm iterates over the family `D` of distance metrics to use for clustering and over the set `K` of candidate values for the optimal `k`. We use K-means clustering on the features and experiment with two distance metrics — Euclidean and Manhattan — to validate our approach's effectiveness in clustering anomalous events. For each distance metric and each value of `k`, we use the K-means algorithm to determine a set of `k` clusters (Line 19) and compute the corresponding value of the inertia (Line 20).

The inertia is determined by measuring the distance between each data point and its centroid and summing the squared errors across all data points. Using the elbow method, we compute the optimal value of `k` (Line 22). This method allows us to identify the point where the rate of decrease sharply slows, forming an *elbow* in the curve. Finally, the set of optimal clusters for the current metrics is added to `optimal_clusters` (Lines 23-24).
